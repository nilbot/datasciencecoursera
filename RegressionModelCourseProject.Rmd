---
title: "Regression Model Course Project"
author: "Ersi Ni"
date: "Jan 20. 2015"
output: rmarkdown::tufte_handout
---

# Introduction

This is the report to our hyperthetical work at *Motor Trend*, looking at the data of a collection of cars. This report delivers the analysis over whether Automatic Transmission or Manual Transmission is better for Miles Per Gallon. 
We argue that that there is a signficant difference between the mean MPG for automatic and manual transmission cars. Manual transmissions achieve a higher value of MPG compared to automatic transmission. The mpg payoff of manual gearing is better if the car weights heavier than 28000 lb

# Anlaysis

```{r, echo=FALSE}
library(datasets)
data(mtcars)
```

A short description of what each variable means in the `mtcars` data set would act as a foreword for this report before we go into detailed analysis:

  * mpg -> our outcome, miles per gallon
  * cyl = numbers of cylinders
  * disp = displacement
  * hp = horse power
  * wt = weight
  * am = our predictor in question, transmission mode (0 for automatic, 1 for manual)
  * gear = number of forward gear
  * carb = number of carburetors


First we look at the linear model for the outcome `mpg` from all predictor variables inside the data set `mtcars`, specifically we look at the coefficients of the linear model:

```{r, echo = F, results='asis'}
library(xtable)
options(xtable.comment = FALSE)
options(xtable.booktabs = TRUE)
xtable(summary(lm(mpg~.,data=mtcars))$coefficients, caption = "P value of linear regression")
```


We noticed that the p value of the coefficients will give us clue as to how much the variable is a factor to the outcome `mpg`. Because the p-value tests the null hypothesis that the coefficient is equal to zero. A low (<0.05) p-value indicates that we can reject this null hypothesis, thus a meaningful variable to our model. Surprisingly our questioned `am` variable is not the lowest of them, but `am` is lower than most others. That means we need to dig deeper.

To support the initial assumption that `am` is indeed a factor of `mpg` response,
we can view the plot of transmission mode over `mpg`.

```{r, echo=FALSE, fig.cap = "Transmission Mode on Miles per Gallon"}
library(ggplot2)
g <- ggplot(mtcars, aes(factor(am),mpg, fill=factor(am)))
g = g +
  geom_boxplot() +
  geom_jitter(position = position_jitter(width = .1, height = 0)) +
  scale_color_discrete(name = "Transmission Mode") +
  scale_fill_discrete(name = "Transmission Mode", breaks = c("0", "1"), labels = c("Automatic", "Manual")) +
  scale_x_discrete(breaks = c("0", "1"), labels = c("Automatic", "Manual")) +
  xlab("")
g

```


From the figure we can see the obvious difference in mean between 2 modes impacting on `mpg`.
We make an hyperthesis test that Ho is `mpg` of manual is less than mpg of automatic, while Ha
is `mpg` of manual is greater than mpg of automatic.

```{r, echo=F}
m1 <- subset(mtcars,mtcars$am==0)
m2 <- subset(mtcars,mtcars$am==1)
t.test(m1,m2,alternative="greater",paired=F)
```

*Now we can say manual transmission has better mpg performance.*

# Quantify the MPG difference

Going back to the first linear model we used at the begining, we know that that summary gives us a clue which variables might be thrown away because they don't appear to be a confounding factor. Step-wise model can deliver that.

```{r}
step_lm <- step(lm(data=mtcars, mpg ~ .), trace = 0)
summary(step_lm)
```

The step model gives us 3 variables `wt`, `qsec` and `am` that can yield a better R-Sqaure. 

Our goal is to find a model with least regressor and highest R-sqaure, the strategy here is comparing several models. To yield a significant difference, we can pick the original all variable model, a model with variables that are highly correlated, a model of `wt` alone and the step-wise model.

The highest correlated variables are 
```{r, echo=FALSE}
head(names(sort(abs(round(cor(mtcars)[1,],2)),decreasing=T)))
```
So we have 

1. `wt+qsec+am` model `r fit1 <- lm(data=mtcars, mpg~wt+qsec+am)`
4. all variable model `r fit2 <- lm(data=mtcars, mpg~.)`
3. `wt` model `r fit3 <- lm(data=mtcars, mpg~wt)`
2. high correlated `wt+cyl+disp+hp` model `r fit4 <- lm(data=mtcars, mpg~wt+cyl+disp+hp)`

Comparing the summaries of these models gives us best $R^2$ of model 1: 0.84

```{r, echo=FALSE}
summary(fit1)
```

We now inspect the residual plots of all models


```{r, fig.margin=T}
r1 <- resid(fit1)
plot(r1, main="model wt+qsec+am")
abline(h=0,lwd=2)
```

```{r, fig.margin=T}
r1 <- resid(fit2)
plot(r1, main="model all variable")
abline(h=0,lwd=2)
```

```{r, fig.margin=T}
r1 <- resid(fit3)
plot(r1, main="model only wt")
abline(h=0,lwd=2)
```

```{r, fig.margin=T}
r1 <- resid(fit4)
plot(r1, main="model wt+cyl+disp+h")
abline(h=0,lwd=2)
```

Model 4 and Model 1 performs closely toe to toe and We will pick model 1 over model 4 because it has fewer variables.

Finally we inspect the plot of created covariant `wt*am`

```{r, echo=FALSE,fig.width = 10, fig.height = 7, fig.fullwidth = TRUE,fig.cap="mpg~wt+am+am*wt"}

fit <- lm(data=mtcars, mpg~wt+am+wt*am)
g1 <- subset(mtcars, mtcars$am==0)
g2 <- subset(mtcars, mtcars$am==1)
plot(g1$wt, g1$mpg, col="lightblue", pch=19, cex=2, xlab="Weight", ylab="mpg")
points(g2$wt, g2$mpg, col="salmon", pch=19, cex=2)
## am=0; 
abline(c(fit$coeff[1], fit$coeff[2]), col="lightblue", lwd=3, lty=2)
## am=1
abline(c(fit$coeff[1]+fit$coeff[3], fit$coeff[2]+fit$coeff[4]), col="salmon", lwd=3, lty=2)
legend("topright", pch=19, col=c("lightblue", "salmon"), legend=c("Manual (am=1)", "Automatic (am=0)"))

```

# Conclusions
We can conclude that: 

- Cars with Manual transmission get more miles per gallon compared to cars with Automatic transmission
- The number of samples with am=0 is less than number of am=1. With the regression lines, the mpg payoff of am=1 is better if wt > 2.8.
